{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot sequence labelling\n",
    "*Credit to https://github.com/marekrei/mltagger*\n",
    "***\n",
    "\n",
    "As mentioned in the author's github above, training phase can be performed with\n",
    "> `python experiment.py config_file.conf`\n",
    "\n",
    "Due to a lack of documentation in the original code, the purpose of this notebook is to break down `experiment.py` to explain how it works.\n",
    "\n",
    "The notebook equivalent of the above command is:\n",
    "> `experiment.run_experiment(config_path)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './conf/fcepublic.conf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING!</b> The following will trigger the full training!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiment.run_experiment(config_path = config_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelude\n",
    "***\n",
    "\n",
    "In order to illustrate how the code functions, the function `run_experiment` in `experiment.py` has been duplicated in the following cell, together with any other dependencies. Note that the function wrapper has been **removed**, thus exposing the local variables and allowing us to view/print them for tutorial purposes.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Run the following cell for tutorial purposes.</b> But it's not necessary to read it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\ipykernel_launcher.py:48: DeprecationWarning: The SafeConfigParser class has been renamed to ConfigParser in Python 3.2. This alias will be removed in future versions. Use ConfigParser directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_train: data/fce/fce-error-detection/tsv/fce-public.train.original.tsv\n",
      "path_dev: data/fce/fce-error-detection/tsv/fce-public.dev.original.tsv\n",
      "path_test: data/fce/fce-error-detection/tsv/fce-public.dev.original.tsv:data/fce/fce-error-detection/tsv/fce-public.test.original.tsv\n",
      "default_label: O\n",
      "model_selector: dev_sent_f:high\n",
      "preload_vectors: embeddings/glove/glove.6B.300d.txt\n",
      "word_embedding_size: 300\n",
      "emb_initial_zero: False\n",
      "train_embeddings: True\n",
      "char_embedding_size: 100\n",
      "word_recurrent_size: 300\n",
      "char_recurrent_size: 100\n",
      "hidden_layer_size: 50\n",
      "char_hidden_layer_size: 50\n",
      "lowercase: True\n",
      "replace_digits: True\n",
      "min_word_freq: -1.0\n",
      "singletons_prob: 0.1\n",
      "allowed_word_length: -1.0\n",
      "max_train_sent_length: -1.0\n",
      "vocab_include_devtest: True\n",
      "vocab_only_embedded: False\n",
      "initializer: glorot\n",
      "opt_strategy: adadelta\n",
      "learningrate: 1.0\n",
      "clip: 0.0\n",
      "batch_equal_size: False\n",
      "max_batch_size: 32\n",
      "epochs: 200\n",
      "stop_if_no_improvement_for_epochs: 7\n",
      "learningrate_decay: 0.9\n",
      "dropout_input: 0.5\n",
      "dropout_word_lstm: 0.5\n",
      "tf_per_process_gpu_memory_fraction: 1.0\n",
      "tf_allow_growth: True\n",
      "lmcost_max_vocab_size: 7500\n",
      "lmcost_hidden_layer_size: 50\n",
      "lmcost_lstm_gamma: 0.0\n",
      "lmcost_joint_lstm_gamma: 0.0\n",
      "lmcost_char_gamma: 0.0\n",
      "lmcost_joint_char_gamma: 0.0\n",
      "char_integration_method: concat\n",
      "save: saved/saved_model.h5\n",
      "load: saved/model_fce.h5\n",
      "garbage_collection: False\n",
      "lstm_use_peepholes: False\n",
      "whidden_layer_size: 200\n",
      "attention_evidence_size: 100\n",
      "attention_activation: soft\n",
      "attention_objective_weight: 0.01\n",
      "sentence_objective_weight: 1.0\n",
      "sentence_objective_persistent: True\n",
      "word_objective_weight: 0.0\n",
      "sentence_composition: attention\n",
      "random_seed: 100\n",
      "n_words: 13470\n",
      "n_chars: 97\n",
      "n_singletons: 6626\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable word_embeddings already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Daniel\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\Daniel\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Daniel\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-18a99b66407f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLTModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_vocabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"preload_vectors\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"preload_vectors\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub_AISG\\mltagger\\model.py\u001b[0m in \u001b[0;36mconstruct_network\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword2id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"word_embedding_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzeros_initializer\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"emb_initial_zero\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m             trainable=(True if self.config[\"train_embeddings\"] == True else False))\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m# This provides a way to lookup the word embeddings based on an input list of word indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1315\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1318\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1319\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    731\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 733\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    734\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable word_embeddings already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\Daniel\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\Daniel\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Daniel\\Anaconda3\\envs\\sequence_labeler\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "# For illustration purposes only\n",
    "# -------------------------------\n",
    "# For code dependencies to function in jupyter, selected functions are manually imported into this cell\n",
    "\n",
    "import collections\n",
    "import numpy\n",
    "import random\n",
    "\n",
    "try:\n",
    "    import ConfigParser as configparser\n",
    "except:\n",
    "    import configparser\n",
    "\n",
    "from model import MLTModel\n",
    "\n",
    "def read_input_files(file_paths, max_sentence_length=-1):\n",
    "    \"\"\"\n",
    "    Reads input files in whitespace-separated format.\n",
    "    Will split file_paths on comma, reading from multiple files.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    line_length = None\n",
    "    for file_path in file_paths.strip().split(\",\"):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            sentence = []\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if len(line) > 0:\n",
    "                    line_parts = line.split()\n",
    "                    assert(len(line_parts) >= 2), line\n",
    "                    assert(len(line_parts) == line_length or line_length == None)\n",
    "                    line_length = len(line_parts)\n",
    "                    sentence.append(line_parts)\n",
    "                elif len(line) == 0 and len(sentence) > 0:\n",
    "                    if max_sentence_length <= 0 or len(sentence) <= max_sentence_length:\n",
    "                        sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            if len(sentence) > 0:\n",
    "                if max_sentence_length <= 0 or len(sentence) <= max_sentence_length:\n",
    "                    sentences.append(sentence)\n",
    "    return sentences\n",
    "    \n",
    "def parse_config(config_section, config_path):\n",
    "    \"\"\"\n",
    "    Reads configuration from the file and returns a dictionary.\n",
    "    Tries to guess the correct datatype for each of the config values.\n",
    "    \"\"\"\n",
    "    config_parser = configparser.SafeConfigParser(allow_no_value=True)\n",
    "    config_parser.read(config_path)\n",
    "    config = collections.OrderedDict()\n",
    "    for key, value in config_parser.items(config_section):\n",
    "        if value is None or len(value.strip()) == 0:\n",
    "            config[key] = None\n",
    "        elif value.lower() in [\"true\", \"false\"]:\n",
    "            config[key] = config_parser.getboolean(config_section, key)\n",
    "        elif value.isdigit():\n",
    "            config[key] = config_parser.getint(config_section, key)\n",
    "        elif is_float(value):\n",
    "            config[key] = config_parser.getfloat(config_section, key)\n",
    "        else:\n",
    "            config[key] = config_parser.get(config_section, key)\n",
    "    return config\n",
    "\n",
    "def is_float(value):\n",
    "    \"\"\"\n",
    "    Check in value is of type float()\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def create_batches_of_sentence_ids(sentences, batch_equal_size, max_batch_size):\n",
    "    \"\"\"\n",
    "    Groups together sentences into batches\n",
    "    If max_batch_size is positive, this value determines the maximum number of sentences in each batch.\n",
    "    If max_batch_size has a negative value, the function dynamically creates the batches such that each batch contains abs(max_batch_size) words.\n",
    "    Returns a list of lists with sentences ids.\n",
    "    \"\"\"\n",
    "    batches_of_sentence_ids = []\n",
    "    if batch_equal_size == True:\n",
    "        sentence_ids_by_length = collections.OrderedDict()\n",
    "        sentence_length_sum = 0.0\n",
    "        for i in range(len(sentences)):\n",
    "            length = len(sentences[i])\n",
    "            if length not in sentence_ids_by_length:\n",
    "                sentence_ids_by_length[length] = []\n",
    "            sentence_ids_by_length[length].append(i)\n",
    "\n",
    "        for sentence_length in sentence_ids_by_length:\n",
    "            if max_batch_size > 0:\n",
    "                batch_size = max_batch_size\n",
    "            else:\n",
    "                batch_size = int((-1 * max_batch_size) / sentence_length)\n",
    "\n",
    "            for i in range(0, len(sentence_ids_by_length[sentence_length]), batch_size):\n",
    "                batches_of_sentence_ids.append(sentence_ids_by_length[sentence_length][i:i + batch_size])\n",
    "    else:\n",
    "        current_batch = []\n",
    "        max_sentence_length = 0\n",
    "        for i in range(len(sentences)):\n",
    "            current_batch.append(i)\n",
    "            if len(sentences[i]) > max_sentence_length:\n",
    "                max_sentence_length = len(sentences[i])\n",
    "            if (max_batch_size > 0 and len(current_batch) >= max_batch_size) \\\n",
    "              or (max_batch_size <= 0 and len(current_batch)*max_sentence_length >= (-1 * max_batch_size)):\n",
    "                batches_of_sentence_ids.append(current_batch)\n",
    "                current_batch = []\n",
    "                max_sentence_length = 0\n",
    "        if len(current_batch) > 0:\n",
    "            batches_of_sentence_ids.append(current_batch)\n",
    "    return batches_of_sentence_ids\n",
    "    \n",
    "# The following originally belonged to function 'run_experiment'\n",
    "# Variables are no longer contained within the function and can be called within this notebook's scope\n",
    "\n",
    "# def run_experiment(config_path):\n",
    "\n",
    "config = parse_config(\"config\", config_path)\n",
    "temp_model_path = config_path + \".model\"\n",
    "if \"random_seed\" in config:\n",
    "    random.seed(config[\"random_seed\"])\n",
    "    numpy.random.seed(config[\"random_seed\"])\n",
    "\n",
    "for key, val in config.items():\n",
    "    print(str(key) + \": \" + str(val))\n",
    "\n",
    "data_train, data_dev, data_test = None, None, None\n",
    "if config[\"path_train\"] != None and len(config[\"path_train\"]) > 0:\n",
    "    data_train = read_input_files(config[\"path_train\"], config[\"max_train_sent_length\"])\n",
    "if config[\"path_dev\"] != None and len(config[\"path_dev\"]) > 0:\n",
    "    data_dev = read_input_files(config[\"path_dev\"])\n",
    "if config[\"path_test\"] != None and len(config[\"path_test\"]) > 0:\n",
    "    data_test = []\n",
    "    for path_test in config[\"path_test\"].strip().split(\":\"):\n",
    "        data_test += read_input_files(path_test)\n",
    "\n",
    "model = MLTModel(config)\n",
    "model.build_vocabs(data_train, data_dev, data_test, config[\"preload_vectors\"])\n",
    "model.construct_network()\n",
    "model.initialize_session()\n",
    "if config[\"preload_vectors\"] != None:\n",
    "    model.preload_word_embeddings(config[\"preload_vectors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Breakdown\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `run_experiment`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use python's inbuilt `configparser` which creates a dictionary from a specifically-structured configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def run_experiment(config_path):\n",
    "    config = parse_config(\"config\", config_path)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read in the data files, assuming the relevant file paths are filled up in the config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def run_experiment(config_path):\n",
    "    ...    \n",
    "    if config[\"path_train\"] != None and len(config[\"path_train\"]) > 0:\n",
    "        data_train = read_input_files(config[\"path_train\"], config[\"max_train_sent_length\"])\n",
    "    if config[\"path_dev\"] != None and len(config[\"path_dev\"]) > 0:\n",
    "        data_dev = read_input_files(config[\"path_dev\"])\n",
    "    if config[\"path_test\"] != None and len(config[\"path_test\"]) > 0:\n",
    "        data_test = []\n",
    "        for path_test in config[\"path_test\"].strip().split(\":\"):\n",
    "            data_test += read_input_files(path_test)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train:\n",
      "-----------\n",
      "Number of sentences: 28731\n",
      "Sample sentences:\n",
      "[['Dear', 'c'], ['Sir', 'c'], ['or', 'c'], ['Madam', 'c'], [',', 'c']]\n",
      "\n",
      "[['You', 'c'], ['promised', 'c'], ['a', 'c'], ['perfect', 'c'], ['evening', 'c'], ['but', 'c'], ['it', 'c'], ['became', 'c'], ['a', 'c'], ['big', 'c'], ['disastrous', 'i'], ['!', 'c']]\n",
      "\n",
      "[['If', 'c'], ['weather', 'i'], ['is', 'c'], ['hot', 'c'], ['then', 'c'], ['we', 'c'], ['do', 'c'], [\"n't\", 'c'], ['have', 'c'], ['to', 'c'], ['wear', 'c'], ['under', 'i'], ['wear', 'i'], ['because', 'c'], ['very', 'c'], ['thin', 'c'], ['and', 'c'], ['light', 'c'], ['clothes', 'c'], ['will', 'c'], ['support', 'c'], ['our', 'c'], ['bodies', 'c'], ['.', 'c']]\n"
     ]
    }
   ],
   "source": [
    "print('data_train:\\n-----------\\nNumber of sentences: {}\\nSample sentences:\\n{}\\n\\n{}\\n\\n{}'\n",
    "      .format(len(data_train), data_train[0], data_train[7], data_train[50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Initializes an instance of the `MTLmodel`, a class defined in `model.py` which serves as the model base on which training, inference, and other operations can be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def run_experiment(config_path):\n",
    "    ...\n",
    "    model = MLTModel(config)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Initalizes index lookup dictionaries (`self.word2id`, `self.char2id`, `self.singletons`) which are used to convert input data from text to indices for proper input into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def run_experiment(config_path):\n",
    "    ...\n",
    "    model.build_vocabs(data_train, data_dev, data_test, config[\"preload_vectors\"])\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('<unk>', 0),\n",
       "             ('.', 1),\n",
       "             ('i', 2),\n",
       "             ('the', 3),\n",
       "             (',', 4),\n",
       "             ('to', 5),\n",
       "             ('and', 6),\n",
       "             ('you', 7),\n",
       "             ('in', 8),\n",
       "             ('a', 9),\n",
       "             ('of', 10),\n",
       "             ('it', 11),\n",
       "             ('was', 12),\n",
       "             ('that', 13),\n",
       "             ('is', 14),\n",
       "             ('for', 15),\n",
       "             ('my', 16),\n",
       "             ('have', 17),\n",
       "             ('we', 18),\n",
       "             ('be', 19),\n",
       "             ('at', 20),\n",
       "             ('would', 21),\n",
       "             ('but', 22),\n",
       "             ('your', 23),\n",
       "             ('because', 24),\n",
       "             (\"n't\", 25),\n",
       "             ('me', 26),\n",
       "             ('like', 27),\n",
       "             ('very', 28),\n",
       "             ('not', 29),\n",
       "             ('this', 30),\n",
       "             ('are', 31),\n",
       "             ('with', 32),\n",
       "             ('will', 33),\n",
       "             ('on', 34),\n",
       "             ('about', 35),\n",
       "             ('as', 36),\n",
       "             ('all', 37),\n",
       "             ('do', 38),\n",
       "             ('am', 39),\n",
       "             ('so', 40),\n",
       "             ('can', 41),\n",
       "             ('there', 42),\n",
       "             ('had', 43),\n",
       "             ('show', 44),\n",
       "             ('from', 45),\n",
       "             ('they', 46),\n",
       "             ('if', 47),\n",
       "             ('time', 48),\n",
       "             ('people', 49),\n",
       "             ('\"', 50),\n",
       "             ('some', 51),\n",
       "             ('when', 52),\n",
       "             ('could', 53),\n",
       "             (\"'s\", 54),\n",
       "             ('our', 55),\n",
       "             ('were', 56),\n",
       "             ('or', 57),\n",
       "             ('dear', 58),\n",
       "             ('think', 59),\n",
       "             ('which', 60),\n",
       "             ('!', 61),\n",
       "             ('good', 62),\n",
       "             ('?', 63),\n",
       "             ('more', 64),\n",
       "             ('what', 65),\n",
       "             ('go', 66),\n",
       "             ('money', 67),\n",
       "             ('one', 68),\n",
       "             ('know', 69),\n",
       "             ('life', 70),\n",
       "             ('shopping', 71),\n",
       "             ('also', 72),\n",
       "             ('first', 73),\n",
       "             ('how', 74),\n",
       "             (\"'m\", 75),\n",
       "             ('only', 76),\n",
       "             ('yours', 77),\n",
       "             ('she', 78),\n",
       "             ('an', 79),\n",
       "             ('he', 80),\n",
       "             ('them', 81),\n",
       "             ('really', 82),\n",
       "             ('clothes', 83),\n",
       "             ('by', 84),\n",
       "             ('much', 85),\n",
       "             ('want', 86),\n",
       "             ('see', 87),\n",
       "             ('other', 88),\n",
       "             ('theatre', 89),\n",
       "             ('should', 90),\n",
       "             ('been', 91),\n",
       "             ('letter', 92),\n",
       "             ('after', 93),\n",
       "             ('her', 94),\n",
       "             ('take', 95),\n",
       "             ('school', 96),\n",
       "             ('has', 97),\n",
       "             ('pat', 98),\n",
       "             ('us', 99),\n",
       "             ('need', 100),\n",
       "             ('going', 101),\n",
       "             ('did', 102),\n",
       "             ('last', 103),\n",
       "             ('forward', 104),\n",
       "             (':', 105),\n",
       "             ('concert', 106),\n",
       "             ('make', 107),\n",
       "             ('lot', 108),\n",
       "             ('just', 109),\n",
       "             ('their', 110),\n",
       "             ('day', 111),\n",
       "             ('july', 112),\n",
       "             ('advertisement', 113),\n",
       "             ('who', 114),\n",
       "             ('technology', 115),\n",
       "             ('two', 116),\n",
       "             ('started', 117),\n",
       "             ('get', 118),\n",
       "             ('back', 119),\n",
       "             ('writing', 120),\n",
       "             ('most', 121),\n",
       "             ('best', 122),\n",
       "             ('sincerely', 123),\n",
       "             ('give', 124),\n",
       "             ('london', 125),\n",
       "             ('out', 126),\n",
       "             ('evening', 127),\n",
       "             ('things', 128),\n",
       "             ('went', 129),\n",
       "             ('any', 130),\n",
       "             ('00', 131),\n",
       "             ('activities', 132),\n",
       "             ('always', 133),\n",
       "             ('now', 134),\n",
       "             ('many', 135),\n",
       "             ('great', 136),\n",
       "             ('up', 137),\n",
       "             ('looking', 138),\n",
       "             ('tell', 139),\n",
       "             ('different', 140),\n",
       "             ('hope', 141),\n",
       "             ('restaurant', 142),\n",
       "             ('thank', 143),\n",
       "             ('travel', 144),\n",
       "             ('information', 145),\n",
       "             ('told', 146),\n",
       "             ('students', 147),\n",
       "             ('something', 148),\n",
       "             ('camp', 149),\n",
       "             ('thing', 150),\n",
       "             ('look', 151),\n",
       "             ('well', 152),\n",
       "             ('musical', 153),\n",
       "             ('new', 154),\n",
       "             ('too', 155),\n",
       "             ('hearing', 156),\n",
       "             ('ask', 157),\n",
       "             ('never', 158),\n",
       "             ('than', 159),\n",
       "             ('him', 160),\n",
       "             ('before', 161),\n",
       "             ('during', 162),\n",
       "             ('help', 163),\n",
       "             ('home', 164),\n",
       "             ('then', 165),\n",
       "             ('his', 166),\n",
       "             ('closed', 167),\n",
       "             ('kind', 168),\n",
       "             ('danny', 169),\n",
       "             ('no', 170),\n",
       "             ('prefer', 171),\n",
       "             ('work', 172),\n",
       "             ('even', 173),\n",
       "             (\"'\", 174),\n",
       "             ('brook', 175),\n",
       "             ('soon', 176),\n",
       "             ('place', 177),\n",
       "             ('friends', 178),\n",
       "             ('say', 179),\n",
       "             ('years', 180),\n",
       "             ('way', 181),\n",
       "             ('stay', 182),\n",
       "             ('play', 183),\n",
       "             ('however', 184),\n",
       "             ('fashion', 185),\n",
       "             ('next', 186),\n",
       "             ('buy', 187),\n",
       "             ('every', 188),\n",
       "             ('find', 189),\n",
       "             ('said', 190),\n",
       "             ('actor', 191),\n",
       "             ('these', 192),\n",
       "             ('over', 193),\n",
       "             (\"'ve\", 194),\n",
       "             ('another', 195),\n",
       "             ('visit', 196),\n",
       "             ('modern', 197),\n",
       "             ('experience', 198),\n",
       "             ('year', 199),\n",
       "             ('important', 200),\n",
       "             ('faithfully', 201),\n",
       "             ('without', 202),\n",
       "             ('got', 203),\n",
       "             ('finally', 204),\n",
       "             ('00:00', 205),\n",
       "             ('friend', 206),\n",
       "             ('wear', 207),\n",
       "             ('love', 208),\n",
       "             ('everything', 209),\n",
       "             ('free', 210),\n",
       "             ('-', 211),\n",
       "             ('interesting', 212),\n",
       "             ('such', 213),\n",
       "             ('where', 214),\n",
       "             ('asked', 215),\n",
       "             ('why', 216),\n",
       "             ('happy', 217),\n",
       "             ('enjoyable', 218),\n",
       "             ('world', 219),\n",
       "             ('must', 220),\n",
       "             ('ryan', 221),\n",
       "             ('enjoy', 222),\n",
       "             ('change', 223),\n",
       "             ('discounts', 224),\n",
       "             (')', 225),\n",
       "             ('log', 226),\n",
       "             ('0', 227),\n",
       "             ('computer', 228),\n",
       "             ('june', 229),\n",
       "             ('famous', 230),\n",
       "             ('california', 231),\n",
       "             ('(', 232),\n",
       "             ('changed', 233),\n",
       "             ('festival', 234),\n",
       "             ('class', 235),\n",
       "             ('month', 236),\n",
       "             ('won', 237),\n",
       "             ('available', 238),\n",
       "             ('00.00', 239),\n",
       "             ('use', 240),\n",
       "             ('swimming', 241),\n",
       "             ('possible', 242),\n",
       "             ('prize', 243),\n",
       "             ('same', 244),\n",
       "             ('holiday', 245),\n",
       "             ('week', 246),\n",
       "             ('00th', 247),\n",
       "             ('tents', 248),\n",
       "             ('daily', 249),\n",
       "             ('competition', 250),\n",
       "             ('used', 251),\n",
       "             (\"'ll\", 252),\n",
       "             ('days', 253),\n",
       "             (\"'d\", 254),\n",
       "             ('future', 255),\n",
       "             ('spend', 256),\n",
       "             ('ticket', 257),\n",
       "             ('wanted', 258),\n",
       "             ('made', 259),\n",
       "             ('start', 260),\n",
       "             ('ca', 261),\n",
       "             ('better', 262),\n",
       "             ('minutes', 263),\n",
       "             ('able', 264),\n",
       "             ('choose', 265),\n",
       "             ('perfect', 266),\n",
       "             ('programme', 267),\n",
       "             ('big', 268),\n",
       "             ('saw', 269),\n",
       "             ('part', 270),\n",
       "             ('unfortunately', 271),\n",
       "             ('end', 272),\n",
       "             ('hotel', 273),\n",
       "             ('disappointed', 274),\n",
       "             ('leisure', 275),\n",
       "             ('long', 276),\n",
       "             ('live', 277),\n",
       "             ('idea', 278),\n",
       "             ('rainbow', 279),\n",
       "             ('secrets', 280),\n",
       "             ('since', 281),\n",
       "             ('tent', 282),\n",
       "             ('tickets', 283),\n",
       "             ('tennis', 284),\n",
       "             ('party', 285),\n",
       "             ('write', 286),\n",
       "             ('example', 287),\n",
       "             ('please', 288),\n",
       "             ('hand', 289),\n",
       "             ('let', 290),\n",
       "             ('sir', 291),\n",
       "             ('bring', 292),\n",
       "             ('kim', 293),\n",
       "             ('secondly', 294),\n",
       "             ('problem', 295),\n",
       "             ('especially', 296),\n",
       "             ('0000', 297),\n",
       "             ('course', 298),\n",
       "             ('nice', 299),\n",
       "             ('decided', 300),\n",
       "             ('weeks', 301),\n",
       "             ('pop', 302),\n",
       "             ('conference', 303),\n",
       "             ('firstly', 304),\n",
       "             ('feel', 305),\n",
       "             ('bad', 306),\n",
       "             ('opinion', 307),\n",
       "             (';', 308),\n",
       "             ('being', 309),\n",
       "             ('job', 310),\n",
       "             ('family', 311),\n",
       "             ('sometimes', 312),\n",
       "             ('problems', 313),\n",
       "             ('answer', 314),\n",
       "             ('internet', 315),\n",
       "             ('trip', 316),\n",
       "             ('come', 317),\n",
       "             ('fact', 318),\n",
       "             ('try', 319),\n",
       "             ('keeping', 320),\n",
       "             ('opportunity', 321),\n",
       "             ('night', 322),\n",
       "             ('basketball', 323),\n",
       "             ('around', 324),\n",
       "             ('house', 325),\n",
       "             ('knew', 326),\n",
       "             ('doing', 327),\n",
       "             ('quite', 328),\n",
       "             ('student', 329),\n",
       "             ('questions', 330),\n",
       "             ('helen', 331),\n",
       "             ('museum', 332),\n",
       "             ('disappointing', 333),\n",
       "             ('instead', 334),\n",
       "             ('cabins', 335),\n",
       "             ('believe', 336),\n",
       "             ('old', 337),\n",
       "             ('while', 338),\n",
       "             ('ago', 339),\n",
       "             ('although', 340),\n",
       "             ('few', 341),\n",
       "             ('again', 342),\n",
       "             ('into', 343),\n",
       "             ('parents', 344),\n",
       "             ('read', 345),\n",
       "             ('group', 346),\n",
       "             ('found', 347),\n",
       "             ('reason', 348),\n",
       "             ('hear', 349),\n",
       "             ('everybody', 350),\n",
       "             ('may', 351),\n",
       "             ('came', 352),\n",
       "             ('everyone', 353),\n",
       "             ('seen', 354),\n",
       "             ('chance', 355),\n",
       "             ('science', 356),\n",
       "             ('sports', 357),\n",
       "             ('lessons', 358),\n",
       "             ('order', 359),\n",
       "             ('point', 360),\n",
       "             ('mrs', 361),\n",
       "             ('thought', 362),\n",
       "             ('secret', 363),\n",
       "             ('anything', 364),\n",
       "             ('keep', 365),\n",
       "             ('...', 366),\n",
       "             ('enough', 367),\n",
       "             ('still', 368),\n",
       "             ('complain', 369),\n",
       "             ('afternoon', 370),\n",
       "             ('suggest', 371),\n",
       "             ('took', 372),\n",
       "             ('sure', 373),\n",
       "             ('discount', 374),\n",
       "             ('pay', 375),\n",
       "             ('accommodation', 376),\n",
       "             ('circle', 377),\n",
       "             ('small', 378),\n",
       "             ('tuesday', 379),\n",
       "             ('talk', 380),\n",
       "             ('little', 381),\n",
       "             ('building', 382),\n",
       "             ('here', 383),\n",
       "             ('special', 384),\n",
       "             ('wait', 385),\n",
       "             ('lots', 386),\n",
       "             ('photography', 387),\n",
       "             ('car', 388),\n",
       "             ('playing', 389),\n",
       "             ('until', 390),\n",
       "             ('late', 391),\n",
       "             ('right', 392),\n",
       "             ('wonderful', 393),\n",
       "             ('having', 394),\n",
       "             ('rules', 395),\n",
       "             ('college', 396),\n",
       "             ('main', 397),\n",
       "             ('summer', 398),\n",
       "             ('person', 399),\n",
       "             ('phone', 400),\n",
       "             ('mr', 401),\n",
       "             ('later', 402),\n",
       "             ('food', 403),\n",
       "             ('city', 404),\n",
       "             ('each', 405),\n",
       "             ('moreover', 406),\n",
       "             ('music', 407),\n",
       "             ('stars', 408),\n",
       "             ('received', 409),\n",
       "             ('already', 410),\n",
       "             ('second', 411),\n",
       "             ('three', 412),\n",
       "             ('cabin', 413),\n",
       "             ('english', 414),\n",
       "             ('those', 415),\n",
       "             ('reply', 416),\n",
       "             ('weather', 417),\n",
       "             ('sport', 418),\n",
       "             ('addition', 419),\n",
       "             ('enjoyed', 420),\n",
       "             ('therefore', 421),\n",
       "             ('might', 422),\n",
       "             ('imagine', 423),\n",
       "             ('film', 424),\n",
       "             ('holidays', 425),\n",
       "             ('man', 426),\n",
       "             ('morning', 427),\n",
       "             ('learn', 428),\n",
       "             ('interested', 429),\n",
       "             ('fun', 430),\n",
       "             ('hall', 431),\n",
       "             ('does', 432),\n",
       "             ('international', 433),\n",
       "             ('comfortable', 434),\n",
       "             ('send', 435),\n",
       "             ('written', 436),\n",
       "             ('shop', 437),\n",
       "             ('stage', 438),\n",
       "             ('both', 439),\n",
       "             ('art', 440),\n",
       "             ('put', 441),\n",
       "             ('waiting', 442),\n",
       "             ('finished', 443),\n",
       "             ('whole', 444),\n",
       "             ('price', 445),\n",
       "             ('painting', 446),\n",
       "             ('children', 447),\n",
       "             ('understand', 448),\n",
       "             ('spent', 449),\n",
       "             ('question', 450),\n",
       "             ('done', 451),\n",
       "             ('shops', 452),\n",
       "             ('climbing', 453),\n",
       "             ('august', 454),\n",
       "             ('madam', 455),\n",
       "             ('felt', 456),\n",
       "             ('march', 457),\n",
       "             ('thanks', 458),\n",
       "             ('nowadays', 459),\n",
       "             ('ever', 460),\n",
       "             ('countries', 461),\n",
       "             ('surfing', 462),\n",
       "             ('own', 463),\n",
       "             ('reasons', 464),\n",
       "             ('far', 465),\n",
       "             ('hard', 466),\n",
       "             ('hours', 467),\n",
       "             ('myself', 468),\n",
       "             ('five', 469),\n",
       "             ('arrived', 470),\n",
       "             ('actually', 471),\n",
       "             ('story', 472),\n",
       "             ('rather', 473),\n",
       "             ('bus', 474),\n",
       "             ('exciting', 475),\n",
       "             ('book', 476),\n",
       "             ('country', 477),\n",
       "             ('manager', 478),\n",
       "             ('working', 479),\n",
       "             ('computers', 480),\n",
       "             ('robertson', 481),\n",
       "             ('easy', 482),\n",
       "             ('glad', 483),\n",
       "             ('town', 484),\n",
       "             ('happened', 485),\n",
       "             ('supposed', 486),\n",
       "             ('someone', 487),\n",
       "             ('lives', 488),\n",
       "             ('maybe', 489),\n",
       "             ('helped', 490),\n",
       "             ('allowed', 491),\n",
       "             ('moment', 492),\n",
       "             ('conclusion', 493),\n",
       "             ('expected', 494),\n",
       "             ('eat', 495),\n",
       "             ('latest', 496),\n",
       "             ('true', 497),\n",
       "             ('singing', 498),\n",
       "             ('further', 499),\n",
       "             ('pleased', 500),\n",
       "             ('according', 501),\n",
       "             ('difficult', 502),\n",
       "             ('hour', 503),\n",
       "             ('mother', 504),\n",
       "             ('private', 505),\n",
       "             ('near', 506),\n",
       "             ('news', 507),\n",
       "             ('room', 508),\n",
       "             ('often', 509),\n",
       "             ('between', 510),\n",
       "             ('living', 511),\n",
       "             ('helping', 512),\n",
       "             ('sleep', 513),\n",
       "             ('arts', 514),\n",
       "             ('recently', 515),\n",
       "             ('called', 516),\n",
       "             ('times', 517),\n",
       "             ('actors', 518),\n",
       "             ('others', 519),\n",
       "             ('angry', 520),\n",
       "             ('anyway', 521),\n",
       "             ('activity', 522),\n",
       "             ('000', 523),\n",
       "             ('name', 524),\n",
       "             ('weekend', 525),\n",
       "             ('sir/madam', 526),\n",
       "             ('artists', 527),\n",
       "             ('almost', 528),\n",
       "             ('films', 529),\n",
       "             ('nothing', 530),\n",
       "             ('university', 531),\n",
       "             (\"'re\", 532),\n",
       "             ('palace', 533),\n",
       "             ('teacher', 534),\n",
       "             ('become', 535),\n",
       "             ('advertisment', 536),\n",
       "             ('meet', 537),\n",
       "             ('six', 538),\n",
       "             ('down', 539),\n",
       "             ('easier', 540),\n",
       "             ('exhibition', 541),\n",
       "             ('bought', 542),\n",
       "             ('plays', 543),\n",
       "             ('video', 544),\n",
       "             ('bit', 545),\n",
       "             ('full', 546),\n",
       "             ('off', 547),\n",
       "             ('tv', 548),\n",
       "             ('smith', 549),\n",
       "             ('favourite', 550),\n",
       "             ('taking', 551),\n",
       "             ('though', 552),\n",
       "             ('view', 553),\n",
       "             ('heard', 554),\n",
       "             ('wo', 555),\n",
       "             ('gave', 556),\n",
       "             ('sorry', 557),\n",
       "             ('front', 558),\n",
       "             ('using', 559),\n",
       "             ('grateful', 560),\n",
       "             ('team', 561),\n",
       "             ('played', 562),\n",
       "             ('else', 563),\n",
       "             ('walk', 564),\n",
       "             ('sailing', 565),\n",
       "             ('past', 566),\n",
       "             ('places', 567),\n",
       "             ('short', 568),\n",
       "             ('its', 569),\n",
       "             ('furthermore', 570),\n",
       "             ('busy', 571),\n",
       "             ('liked', 572),\n",
       "             ('beautiful', 573),\n",
       "             ('seeing', 574),\n",
       "             ('young', 575),\n",
       "             ('makes', 576),\n",
       "             ('shows', 577),\n",
       "             ('useful', 578),\n",
       "             ('getting', 579),\n",
       "             ('tina', 580),\n",
       "             ('suitable', 581),\n",
       "             ('accomodation', 582),\n",
       "             ('surprise', 583),\n",
       "             ('less', 584),\n",
       "             ('once', 585),\n",
       "             ('watch', 586),\n",
       "             ('wrong', 587),\n",
       "             ('present', 588),\n",
       "             ('mind', 589),\n",
       "             ('explain', 590),\n",
       "             ('events', 591),\n",
       "             ('golf', 592),\n",
       "             ('met', 593),\n",
       "             ('maria', 594),\n",
       "             ('half', 595),\n",
       "             ('expensive', 596),\n",
       "             ('concerts', 597),\n",
       "             ('telephone', 598),\n",
       "             ('nobody', 599),\n",
       "             ('excited', 600),\n",
       "             ('halls', 601),\n",
       "             ('keen', 602),\n",
       "             ('dangerous', 603),\n",
       "             ('least', 604),\n",
       "             ('together', 605),\n",
       "             ('away', 606),\n",
       "             ('nature', 607),\n",
       "             ('forget', 608),\n",
       "             ('began', 609),\n",
       "             ('study', 610),\n",
       "             ('writting', 611),\n",
       "             ('band', 612),\n",
       "             ('dinner', 613),\n",
       "             ('became', 614),\n",
       "             ('thinking', 615),\n",
       "             ('mr.', 616),\n",
       "             ('suggestion', 617),\n",
       "             ('light', 618),\n",
       "             ('call', 619),\n",
       "             ('contact', 620),\n",
       "             ('mobile', 621),\n",
       "             ('truelove', 622),\n",
       "             ('fashions', 623),\n",
       "             ('central', 624),\n",
       "             ('starring', 625),\n",
       "             ('receive', 626),\n",
       "             ('â£', 627),\n",
       "             ('high', 628),\n",
       "             ('remember', 629),\n",
       "             ('centre', 630),\n",
       "             ('journalists', 631),\n",
       "             ('today', 632),\n",
       "             ('inform', 633),\n",
       "             ('refund', 634),\n",
       "             ('father', 635),\n",
       "             ('details', 636),\n",
       "             ('booked', 637),\n",
       "             ('teachers', 638),\n",
       "             ('real', 639),\n",
       "             ('appreciate', 640),\n",
       "             ('wednesday', 641),\n",
       "             ('due', 642),\n",
       "             ('filmed', 643),\n",
       "             ('worst', 644),\n",
       "             ('lesson', 645),\n",
       "             ('singer', 646),\n",
       "             ('following', 647),\n",
       "             ('area', 648),\n",
       "             ('consider', 649),\n",
       "             ('staying', 650),\n",
       "             ('boring', 651),\n",
       "             ('asking', 652),\n",
       "             ('usually', 653),\n",
       "             ('wish', 654),\n",
       "             ('number', 655),\n",
       "             ('camping', 656),\n",
       "             ('hairstyles', 657),\n",
       "             ('making', 658),\n",
       "             ('talking', 659),\n",
       "             ('fantastic', 660),\n",
       "             ('ten', 661),\n",
       "             ('tried', 662),\n",
       "             ('close', 663),\n",
       "             ('agree', 664),\n",
       "             ('excellent', 665),\n",
       "             ('exams', 666),\n",
       "             ('paid', 667),\n",
       "             ('mentioned', 668),\n",
       "             ('human', 669),\n",
       "             ('left', 670),\n",
       "             ('wrote', 671),\n",
       "             ('situation', 672),\n",
       "             ('changing', 673),\n",
       "             ('miss', 674),\n",
       "             ('invention', 675),\n",
       "             ('terrible', 676),\n",
       "             ('despite', 677),\n",
       "             ('buying', 678),\n",
       "             ('attention', 679),\n",
       "             ('sum', 680),\n",
       "             ('completely', 681),\n",
       "             ('women', 682),\n",
       "             ('organised', 683),\n",
       "             ('finish', 684),\n",
       "             ('promised', 685),\n",
       "             ('performance', 686),\n",
       "             ('besides', 687),\n",
       "             ('clark', 688),\n",
       "             ('style', 689),\n",
       "             ('mean', 690),\n",
       "             ('visiting', 691),\n",
       "             ('needed', 692),\n",
       "             ('speak', 693),\n",
       "             ('ones', 694),\n",
       "             ('starts', 695),\n",
       "             ('prepare', 696),\n",
       "             ('staff', 697),\n",
       "             ('leave', 698),\n",
       "             ('wishes', 699),\n",
       "             ('given', 700),\n",
       "             ('months', 701),\n",
       "             ('case', 702),\n",
       "             ('necessary', 703),\n",
       "             ('history', 704),\n",
       "             ('probably', 705),\n",
       "             ('report', 706),\n",
       "             ('event', 707),\n",
       "             ('begin', 708),\n",
       "             (\"o'clock\", 709),\n",
       "             ('walking', 710),\n",
       "             ('ways', 711),\n",
       "             ('wich', 712),\n",
       "             ('quickly', 713),\n",
       "             ('somebody', 714),\n",
       "             ('cannot', 715),\n",
       "             ('matter', 716),\n",
       "             ('rest', 717),\n",
       "             ('worse', 718),\n",
       "             ('child', 719),\n",
       "             ('exam', 720),\n",
       "             ('result', 721),\n",
       "             ('ms', 722),\n",
       "             ('stop', 723),\n",
       "             ('care', 724),\n",
       "             ('takes', 725),\n",
       "             ('side', 726),\n",
       "             ('television', 727),\n",
       "             ('chose', 728),\n",
       "             ('beginning', 729),\n",
       "             ('street', 730),\n",
       "             ('popular', 731),\n",
       "             ('drink', 732),\n",
       "             ('fine', 733),\n",
       "             ('personal', 734),\n",
       "             ('shoes', 735),\n",
       "             ('list', 736),\n",
       "             ('several', 737),\n",
       "             ('suddenly', 738),\n",
       "             ('hot', 739),\n",
       "             ('jane', 740),\n",
       "             ('classes', 741),\n",
       "             ('possibility', 742),\n",
       "             ('anyone', 743),\n",
       "             ('singers', 744),\n",
       "             ('known', 745),\n",
       "             ('surprised', 746),\n",
       "             ('recommend', 747),\n",
       "             ('through', 748),\n",
       "             ('alone', 749),\n",
       "             ('outside', 750),\n",
       "             ('seems', 751),\n",
       "             ('huge', 752),\n",
       "             ('everyday', 753),\n",
       "             ('improve', 754),\n",
       "             ('sound', 755),\n",
       "             ('open', 756),\n",
       "             ('cars', 757),\n",
       "             ('date', 758),\n",
       "             ('listen', 759),\n",
       "             ('choice', 760),\n",
       "             ('sea', 761),\n",
       "             ('afraid', 762),\n",
       "             ('saturday', 763),\n",
       "             ('subject', 764),\n",
       "             ('reading', 765),\n",
       "             ('river', 766),\n",
       "             ('spending', 767),\n",
       "             ('clean', 768),\n",
       "             ('changes', 769),\n",
       "             ('points', 770),\n",
       "             ('boy', 771),\n",
       "             ('worked', 772),\n",
       "             ('pleasure', 773),\n",
       "             ('lights', 774),\n",
       "             ('mrs.', 775),\n",
       "             ('sort', 776),\n",
       "             ('realised', 777),\n",
       "             ('machines', 778),\n",
       "             ('door', 779),\n",
       "             ('dream', 780),\n",
       "             ('amazing', 781),\n",
       "             ('either', 782),\n",
       "             ('concerning', 783),\n",
       "             ('pictures', 784),\n",
       "             ('means', 785),\n",
       "             ('giving', 786),\n",
       "             ('says', 787),\n",
       "             ('informations', 788),\n",
       "             ('national', 789),\n",
       "             ('yourself', 790),\n",
       "             ('water', 791),\n",
       "             ('girl', 792),\n",
       "             ('horrible', 793),\n",
       "             ('pm', 794),\n",
       "             ('girls', 795),\n",
       "             ('books', 796),\n",
       "             ('inside', 797),\n",
       "             ('kinds', 798),\n",
       "             ('birthday', 799),\n",
       "             ('offer', 800),\n",
       "             ('suggestions', 801),\n",
       "             ('technologies', 802),\n",
       "             ('stuff', 803),\n",
       "             ('office', 804),\n",
       "             ('stories', 805),\n",
       "             ('funny', 806),\n",
       "             ('starting', 807),\n",
       "             ('coming', 808),\n",
       "             ('trying', 809),\n",
       "             ('top', 810),\n",
       "             ('public', 811),\n",
       "             ('watching', 812),\n",
       "             ('earn', 813),\n",
       "             ('impossible', 814),\n",
       "             ('visited', 815),\n",
       "             ('company', 816),\n",
       "             ('join', 817),\n",
       "             ('newspaper', 818),\n",
       "             ('lastly', 819),\n",
       "             ('center', 820),\n",
       "             ('yesterday', 821),\n",
       "             ('everywhere', 822),\n",
       "             ('cold', 823),\n",
       "             ('train', 824),\n",
       "             ('men', 825),\n",
       "             ('tired', 826),\n",
       "             ('local', 827),\n",
       "             ('brother', 828),\n",
       "             ('sleeping', 829),\n",
       "             ('usa', 830),\n",
       "             ('noticed', 831),\n",
       "             ('station', 832),\n",
       "             ('studying', 833),\n",
       "             ('favorite', 834),\n",
       "             ('looked', 835),\n",
       "             ('gallery', 836),\n",
       "             ('u.s.a', 837),\n",
       "             ('invented', 838),\n",
       "             ('planned', 839),\n",
       "             ('dress', 840),\n",
       "             ('wearing', 841),\n",
       "             ('chosen', 842),\n",
       "             ('concerned', 843),\n",
       "             ('facilities', 844),\n",
       "             ('expect', 845),\n",
       "             ('apart', 846),\n",
       "             ('break', 847),\n",
       "             ('games', 848),\n",
       "             ('feeling', 849),\n",
       "             ('woman', 850),\n",
       "             ('receiving', 851),\n",
       "             ('type', 852),\n",
       "             ('husband', 853),\n",
       "             ('etc.', 854),\n",
       "             ('held', 855),\n",
       "             ('attend', 856),\n",
       "             ('works', 857),\n",
       "             ('move', 858),\n",
       "             ('regards', 859),\n",
       "             ('relax', 860),\n",
       "             ('meeting', 861),\n",
       "             ('e-mail', 862),\n",
       "             ('happen', 863),\n",
       "             ('nervous', 864),\n",
       "             ('thirdly', 865),\n",
       "             ('wants', 866),\n",
       "             ('express', 867),\n",
       "             ('face', 868),\n",
       "             ('hungry', 869),\n",
       "             ('above', 870),\n",
       "             ('fast', 871),\n",
       "             ('decide', 872),\n",
       "             ('homes', 873),\n",
       "             ('period', 874),\n",
       "             ('0:00', 875),\n",
       "             ('century', 876),\n",
       "             ('return', 877),\n",
       "             ('easily', 878),\n",
       "             ('card', 879),\n",
       "             ('realy', 880),\n",
       "             ('faster', 881),\n",
       "             ('plan', 882),\n",
       "             ('turn', 883),\n",
       "             ('dance', 884),\n",
       "             ('police', 885),\n",
       "             ('saying', 886),\n",
       "             ('simple', 887),\n",
       "             ('anymore', 888),\n",
       "             ('poor', 889),\n",
       "             ('p.m.', 890),\n",
       "             ('waste', 891),\n",
       "             ('extremely', 892),\n",
       "             ('realized', 893),\n",
       "             ('invited', 894),\n",
       "             ('crowded', 895),\n",
       "             ('society', 896),\n",
       "             ('regarding', 897),\n",
       "             ('mention', 898),\n",
       "             ('air', 899),\n",
       "             ('knowledge', 900),\n",
       "             ('follow', 901),\n",
       "             ('service', 902),\n",
       "             ('upset', 903),\n",
       "             ('radio', 904),\n",
       "             ('save', 905),\n",
       "             ('travelling', 906),\n",
       "             ('advertised', 907),\n",
       "             ('telling', 908),\n",
       "             ('bank', 909),\n",
       "             ('sally', 910),\n",
       "             ('gone', 911),\n",
       "             ('advantages', 912),\n",
       "             ('under', 913),\n",
       "             ('entrance', 914),\n",
       "             ('seven', 915),\n",
       "             ('word', 916),\n",
       "             ('wonder', 917),\n",
       "             ('four', 918),\n",
       "             ('taken', 919),\n",
       "             ('aim', 920),\n",
       "             ('respect', 921),\n",
       "             ('common', 922),\n",
       "             ('u.s.a.', 923),\n",
       "             ('friday', 924),\n",
       "             ('ready', 925),\n",
       "             ('organise', 926),\n",
       "             ('early', 927),\n",
       "             ('amount', 928),\n",
       "             ('media', 929),\n",
       "             ('talked', 930),\n",
       "             ('machine', 931),\n",
       "             ('end-of-conference', 932),\n",
       "             ('speaking', 933),\n",
       "             ('boyfriend', 934),\n",
       "             ('yes', 935),\n",
       "             ('practice', 936),\n",
       "             ('practise', 937),\n",
       "             ('turned', 938),\n",
       "             ('lost', 939),\n",
       "             ('swim', 940),\n",
       "             ('club', 941),\n",
       "             ('win', 942),\n",
       "             ('instance', 943),\n",
       "             ('brown', 944),\n",
       "             ('lifes', 945),\n",
       "             ('accept', 946),\n",
       "             ('instruments', 947),\n",
       "             ('absolutely', 948),\n",
       "             ('greenwich', 949),\n",
       "             ('paul', 950),\n",
       "             ('otherwise', 951),\n",
       "             ('eight', 952),\n",
       "             ('wondering', 953),\n",
       "             ('informed', 954),\n",
       "             ('unknown', 955),\n",
       "             ('cause', 956),\n",
       "             ('homework', 957),\n",
       "             ('audience', 958),\n",
       "             ('advice', 959),\n",
       "             ('extra', 960),\n",
       "             ('sad', 961),\n",
       "             ('replaced', 962),\n",
       "             ('inventions', 963),\n",
       "             ('except', 964),\n",
       "             ('drinks', 965),\n",
       "             ('spite', 966),\n",
       "             ('carry', 967),\n",
       "             ('disadvantages', 968),\n",
       "             ('provide', 969),\n",
       "             ('seemed', 970),\n",
       "             ('normal', 971),\n",
       "             ('etc', 972),\n",
       "             ('appeared', 973),\n",
       "             ('competitions', 974),\n",
       "             ('organisation', 975),\n",
       "             ('reference', 976),\n",
       "             ('explained', 977),\n",
       "             ('share', 978),\n",
       "             ('totally', 979),\n",
       "             ('electricity', 980),\n",
       "             ('schools', 981),\n",
       "             ('whatever', 982),\n",
       "             ('confortable', 983),\n",
       "             ('deserve', 984),\n",
       "             ('particularly', 985),\n",
       "             ('ill', 986),\n",
       "             ('strange', 987),\n",
       "             ('notice', 988),\n",
       "             ('rooms', 989),\n",
       "             ('star', 990),\n",
       "             ('lunch', 991),\n",
       "             ('couple', 992),\n",
       "             ('invite', 993),\n",
       "             ('monday', 994),\n",
       "             ('request', 995),\n",
       "             ('formal', 996),\n",
       "             ('hello', 997),\n",
       "             ('spare', 998),\n",
       "             ('quality', 999),\n",
       "             ...])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('<cunk>', 0),\n",
       "             ('e', 1),\n",
       "             ('t', 2),\n",
       "             ('o', 3),\n",
       "             ('a', 4),\n",
       "             ('n', 5),\n",
       "             ('i', 6),\n",
       "             ('s', 7),\n",
       "             ('r', 8),\n",
       "             ('h', 9),\n",
       "             ('l', 10),\n",
       "             ('d', 11),\n",
       "             ('u', 12),\n",
       "             ('y', 13),\n",
       "             ('m', 14),\n",
       "             ('c', 15),\n",
       "             ('w', 16),\n",
       "             ('f', 17),\n",
       "             ('g', 18),\n",
       "             ('p', 19),\n",
       "             ('.', 20),\n",
       "             ('I', 21),\n",
       "             ('b', 22),\n",
       "             ('v', 23),\n",
       "             (',', 24),\n",
       "             ('k', 25),\n",
       "             ('T', 26),\n",
       "             (\"'\", 27),\n",
       "             ('A', 28),\n",
       "             ('S', 29),\n",
       "             ('E', 30),\n",
       "             ('O', 31),\n",
       "             ('D', 32),\n",
       "             ('H', 33),\n",
       "             ('M', 34),\n",
       "             ('W', 35),\n",
       "             ('x', 36),\n",
       "             ('N', 37),\n",
       "             ('F', 38),\n",
       "             ('R', 39),\n",
       "             ('L', 40),\n",
       "             ('C', 41),\n",
       "             ('Y', 42),\n",
       "             ('B', 43),\n",
       "             ('j', 44),\n",
       "             ('0', 45),\n",
       "             ('P', 46),\n",
       "             ('\"', 47),\n",
       "             ('1', 48),\n",
       "             ('U', 49),\n",
       "             ('!', 50),\n",
       "             ('?', 51),\n",
       "             ('-', 52),\n",
       "             ('J', 53),\n",
       "             ('q', 54),\n",
       "             (':', 55),\n",
       "             ('G', 56),\n",
       "             ('z', 57),\n",
       "             ('2', 58),\n",
       "             ('K', 59),\n",
       "             ('V', 60),\n",
       "             ('5', 61),\n",
       "             ('3', 62),\n",
       "             ('9', 63),\n",
       "             ('4', 64),\n",
       "             (')', 65),\n",
       "             ('(', 66),\n",
       "             (';', 67),\n",
       "             ('/', 68),\n",
       "             ('7', 69),\n",
       "             ('6', 70),\n",
       "             ('8', 71),\n",
       "             ('£', 72),\n",
       "             ('Â', 73),\n",
       "             ('X', 74),\n",
       "             ('Ã', 75),\n",
       "             ('Z', 76),\n",
       "             ('Q', 77),\n",
       "             ('&', 78),\n",
       "             ('%', 79),\n",
       "             ('*', 80),\n",
       "             ('©', 81),\n",
       "             ('´', 82),\n",
       "             ('¶', 83),\n",
       "             ('=', 84),\n",
       "             ('«', 85),\n",
       "             ('`', 86),\n",
       "             ('$', 87),\n",
       "             ('ª', 88),\n",
       "             ('¢', 89),\n",
       "             ('¼', 90),\n",
       "             ('¡', 91),\n",
       "             ('±', 92),\n",
       "             ('§', 93),\n",
       "             ('+', 94),\n",
       "             ('|', 95),\n",
       "             ('¤', 96)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.char2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'panfulet',\n",
       " 'show-organization',\n",
       " 'peopel',\n",
       " 'sedentary',\n",
       " 'permision',\n",
       " 'camper',\n",
       " 'avenging',\n",
       " 'conference-organisation',\n",
       " 'disclosed',\n",
       " 'easier.',\n",
       " 'feeding',\n",
       " 'allowe',\n",
       " 'rattanakosin',\n",
       " 'ranked',\n",
       " 'architerture',\n",
       " 'unemploeers',\n",
       " 'techincs',\n",
       " 'museim',\n",
       " 'convidated',\n",
       " 'knowe',\n",
       " 'coluor',\n",
       " 'soilors',\n",
       " '00.00.0',\n",
       " 'concentrat',\n",
       " 'human-being',\n",
       " 'vaccination',\n",
       " 'alleys',\n",
       " 'eate',\n",
       " 'carrots',\n",
       " 'goverments',\n",
       " 'puzzle',\n",
       " 'definity',\n",
       " 'tidy.',\n",
       " 'appartement',\n",
       " 'mananger',\n",
       " 'lightened',\n",
       " 'cream',\n",
       " 'sky-train',\n",
       " 'n0c',\n",
       " 'abandoned',\n",
       " 'owen',\n",
       " 'extreamly',\n",
       " 'funy',\n",
       " 'excpect',\n",
       " 'secontly',\n",
       " 'leter',\n",
       " 'plausible',\n",
       " 'cleanest',\n",
       " 'enumerous',\n",
       " 'tranfer',\n",
       " 'wellknown',\n",
       " 'visites',\n",
       " 'thusday',\n",
       " 'contine',\n",
       " 'batteries',\n",
       " 'persuately',\n",
       " 'pepperoni',\n",
       " 'barkeley',\n",
       " 'flew',\n",
       " 'promissing',\n",
       " 'sigh',\n",
       " 'handled',\n",
       " 'asted',\n",
       " 'tee',\n",
       " 'prapare',\n",
       " 'varys',\n",
       " 'diffences',\n",
       " 'absolutlly',\n",
       " 'anis',\n",
       " 'district',\n",
       " 'accomotation',\n",
       " 'disturbing',\n",
       " 'anser',\n",
       " 'bangkok',\n",
       " 'questionarie',\n",
       " 'climates',\n",
       " 'convinent',\n",
       " 'next-year',\n",
       " 'bully',\n",
       " 'self-satisfaction',\n",
       " 'abe',\n",
       " 'data-bank',\n",
       " 'sweeping',\n",
       " 'uderground',\n",
       " 'apoligised',\n",
       " '00s',\n",
       " 'gangs',\n",
       " 'openion',\n",
       " 'lolas',\n",
       " 'authers',\n",
       " 'regred',\n",
       " 'diffrently',\n",
       " 'online-shopping',\n",
       " 'suit.',\n",
       " 'eviorment',\n",
       " 'helful',\n",
       " 'nower',\n",
       " 'interst',\n",
       " 'fears',\n",
       " 'manuscript',\n",
       " 'worthly',\n",
       " 'pieceful',\n",
       " 'masurian',\n",
       " 'gratfull',\n",
       " 'carlos',\n",
       " 'eclectric',\n",
       " 'outlights',\n",
       " 'loses',\n",
       " 'full-prize',\n",
       " 'shake',\n",
       " 'enderstand',\n",
       " 'immigration',\n",
       " 'calming',\n",
       " 'custumers',\n",
       " 'kyon',\n",
       " 'monery',\n",
       " 'irregularities',\n",
       " 'i.s.o.',\n",
       " 'non-polluted',\n",
       " 'appriciation',\n",
       " 'atrractive',\n",
       " 'um',\n",
       " 'firmly',\n",
       " 'elina',\n",
       " 'mixing',\n",
       " 'surfboard',\n",
       " 'expend',\n",
       " 'grumman',\n",
       " 'edmond',\n",
       " 'characther',\n",
       " 'liberated',\n",
       " 'pathetic',\n",
       " 'compere',\n",
       " 'mango',\n",
       " 'saint-tropez',\n",
       " 'adversitement',\n",
       " 'consense',\n",
       " 'jack-pot',\n",
       " 'salaly',\n",
       " 'innacuracies',\n",
       " 'improvments',\n",
       " 'encryptation',\n",
       " 'eventaully',\n",
       " 'determinate',\n",
       " 'example.',\n",
       " 'disturbe',\n",
       " 'cleaver',\n",
       " 'socked',\n",
       " 'relyied',\n",
       " 'previst',\n",
       " 'rucksack',\n",
       " 'posh',\n",
       " 'sucsess',\n",
       " 'coursework',\n",
       " 'syntetic',\n",
       " 'estimately',\n",
       " 'communiate',\n",
       " 'confortnesscomfortable',\n",
       " 'arctic',\n",
       " 'countryside.',\n",
       " 'uge',\n",
       " 'claryfy',\n",
       " 'mates.',\n",
       " 'shakespear',\n",
       " 'hard-rock',\n",
       " 'carrear',\n",
       " 'regulament',\n",
       " 'proximity',\n",
       " 'bae',\n",
       " 'builded',\n",
       " 'monkey',\n",
       " 'faded',\n",
       " 'suprisingly',\n",
       " 'personnaly',\n",
       " 'illegal',\n",
       " 'bao-yu',\n",
       " 'todi',\n",
       " 'key-word',\n",
       " 'one-to-one',\n",
       " 'slim',\n",
       " 'dissaprove',\n",
       " 'burdens',\n",
       " \"d'mrgell\",\n",
       " 'sizes',\n",
       " 'interviewer',\n",
       " 'vertical',\n",
       " 'agenda',\n",
       " 'effeciently',\n",
       " 'authors',\n",
       " 'kilometer',\n",
       " 'suriphat',\n",
       " 'accelerating',\n",
       " 'matching',\n",
       " '0hw',\n",
       " 'speccial',\n",
       " 'hyatt',\n",
       " 'jule',\n",
       " 'gentleman',\n",
       " 'presently',\n",
       " 'lips',\n",
       " 'recomment',\n",
       " 'dicounts',\n",
       " 'famious',\n",
       " 'becose',\n",
       " 'keyboards',\n",
       " 'presure',\n",
       " 'noting',\n",
       " 'in-depth',\n",
       " 'recommending',\n",
       " 'concernent',\n",
       " 'boo',\n",
       " 'weekend-price',\n",
       " 'cher',\n",
       " 'snaks',\n",
       " 'swimming-school',\n",
       " 'tanizaki',\n",
       " 'agrees',\n",
       " 'desited',\n",
       " 'old-style',\n",
       " 'rehearshals',\n",
       " '000.',\n",
       " 'anyof',\n",
       " 'unfornutely',\n",
       " 'under-paid',\n",
       " 'xviiith',\n",
       " 'helds',\n",
       " 'scottish',\n",
       " '0gh',\n",
       " 'tramits',\n",
       " 'conceited',\n",
       " 'angela',\n",
       " 'showrooms',\n",
       " 'english-speaking',\n",
       " 'andrehi',\n",
       " 'trouses',\n",
       " 'befriended',\n",
       " 'archive',\n",
       " '00.00am',\n",
       " 'advetisement',\n",
       " 'shal',\n",
       " 'counsil',\n",
       " 'faculties',\n",
       " 'effecting',\n",
       " 'schulsson',\n",
       " 'eiffel',\n",
       " 'ouellet',\n",
       " 'swop',\n",
       " 'free.',\n",
       " 'tommy',\n",
       " 'b.h',\n",
       " 'summer-holiday',\n",
       " 'diserve',\n",
       " 'goot',\n",
       " 'aliens',\n",
       " 'agda',\n",
       " 'beleave',\n",
       " 'disadvatatges',\n",
       " 'compleatly',\n",
       " 'tray',\n",
       " 'initial',\n",
       " 'constat',\n",
       " 'mon',\n",
       " 'actors..',\n",
       " 'thanful',\n",
       " 'crasy',\n",
       " 'bewildered',\n",
       " 'e.h',\n",
       " 'caesara',\n",
       " 'accepts',\n",
       " 'well-organized',\n",
       " 'restructurated',\n",
       " 'unbelivebly',\n",
       " 'liao',\n",
       " 'onc',\n",
       " 'phowrung',\n",
       " 'b.h.',\n",
       " 'widest',\n",
       " 'becaming',\n",
       " 'risking',\n",
       " 'disapotted',\n",
       " 'employes',\n",
       " 'mouvement',\n",
       " 'leventina',\n",
       " 'funier',\n",
       " 'ticket-prices',\n",
       " 'strickt',\n",
       " 'actor.',\n",
       " 'aways',\n",
       " 'convincing',\n",
       " 'fluent',\n",
       " 'reconstructed',\n",
       " 'attacts',\n",
       " 'vehicles',\n",
       " 'insead',\n",
       " 'baterist',\n",
       " 'verybody',\n",
       " 'characterize',\n",
       " 'slightly',\n",
       " 'alas',\n",
       " 'somary',\n",
       " 'activist',\n",
       " 'clotches',\n",
       " 'panther',\n",
       " 'neccesity',\n",
       " 'hermitage',\n",
       " 'coloures',\n",
       " 'troussers',\n",
       " 'boring.',\n",
       " 'scarly',\n",
       " 'cassually',\n",
       " 'pactice',\n",
       " 'varaity',\n",
       " 'colaborate',\n",
       " 'acres',\n",
       " 'lacked',\n",
       " 'evining',\n",
       " 'above-mentioned',\n",
       " 'trade',\n",
       " 'recognised.',\n",
       " 'plase',\n",
       " 'fairy',\n",
       " 'untraditional',\n",
       " 'gladiators',\n",
       " 'atlantic',\n",
       " 'don',\n",
       " 'champaign',\n",
       " 'half-a',\n",
       " 'curse',\n",
       " 'on.',\n",
       " 'morell',\n",
       " 'unicef',\n",
       " 'tazief',\n",
       " 'leisure-clothes',\n",
       " 'lavatories',\n",
       " 'inaute',\n",
       " 'comfortible',\n",
       " 'hid',\n",
       " 'conversion',\n",
       " 'porawek',\n",
       " 'honnest',\n",
       " 'apologyse',\n",
       " 'knowledgement',\n",
       " 'denl-a-lion',\n",
       " 'smetana',\n",
       " 'suprem',\n",
       " 'disk',\n",
       " 'enjable',\n",
       " 'professers',\n",
       " 'builders.',\n",
       " 'jon.',\n",
       " 'rumbling',\n",
       " 'cour',\n",
       " 'tairs',\n",
       " 'purchased',\n",
       " 'hopeness',\n",
       " 'cycle',\n",
       " 'pirce',\n",
       " 'cortez',\n",
       " 'textbook',\n",
       " 'maximize',\n",
       " 'ad.',\n",
       " 'joinable',\n",
       " 'aladdin',\n",
       " 'katha',\n",
       " 'www.neuchatel.ch',\n",
       " 'distracted',\n",
       " 'receised',\n",
       " 'box-office',\n",
       " '0.00p.m',\n",
       " 'trainings',\n",
       " '0:00pm',\n",
       " 'full-growns',\n",
       " 'brocher',\n",
       " 'housekeeper',\n",
       " 'mondays',\n",
       " 'verey',\n",
       " 'vittoria',\n",
       " 'occuried',\n",
       " 'tribute',\n",
       " 'sociatys',\n",
       " 'austrian',\n",
       " 'mask',\n",
       " 'promiss',\n",
       " 'archeology',\n",
       " 'thinked',\n",
       " 'percent',\n",
       " 'eighteenth',\n",
       " 'mediocre',\n",
       " 'indentity',\n",
       " 'paticulaly',\n",
       " 'imax',\n",
       " 'pet',\n",
       " 'forway',\n",
       " 'recompansate',\n",
       " 'chemnik',\n",
       " 'wagon',\n",
       " 'touristic',\n",
       " 'sapawadee',\n",
       " 'minding',\n",
       " 'shopper',\n",
       " 'facade',\n",
       " 'offerring',\n",
       " 'introduction:-',\n",
       " 'kilogram',\n",
       " 'dropped',\n",
       " 'monitor',\n",
       " 'service.',\n",
       " 'interiors',\n",
       " 'proficient',\n",
       " 'technically',\n",
       " 'grant',\n",
       " 'belter',\n",
       " 'sevendays',\n",
       " 'transfert',\n",
       " 'ennoying',\n",
       " 'physcological',\n",
       " 'controversary',\n",
       " 'enrich',\n",
       " 'wersting',\n",
       " 'lucia',\n",
       " 'desided',\n",
       " 'oblige',\n",
       " 'e-mail.',\n",
       " 'cashpoints',\n",
       " 'lifeã',\n",
       " 'anoyed',\n",
       " 'notwithstanding',\n",
       " 'bolton-market',\n",
       " 'montri',\n",
       " 'appropiet',\n",
       " 'engineers',\n",
       " 'banks',\n",
       " 'aspiration',\n",
       " 'pony-ride',\n",
       " 'volencia',\n",
       " 'clowds',\n",
       " 'references',\n",
       " 'furiture',\n",
       " 'katy',\n",
       " 'exceptions',\n",
       " 'riched',\n",
       " 'imprisonment',\n",
       " 'kaguya',\n",
       " 'enjoyded',\n",
       " 'klein',\n",
       " 'pot-au-fleurs',\n",
       " 'bravely',\n",
       " 'atrophied',\n",
       " 'illness..',\n",
       " 'satified',\n",
       " 'remeber',\n",
       " '0c',\n",
       " 'pleace',\n",
       " 'owl',\n",
       " 'recommen',\n",
       " 'jumpers',\n",
       " 'photographe',\n",
       " 'see-through',\n",
       " 'draws',\n",
       " 'stroll',\n",
       " 'prest',\n",
       " \"we'are\",\n",
       " 'retelling',\n",
       " 'vendors',\n",
       " 'exhibitor',\n",
       " 'instincts',\n",
       " 'faind',\n",
       " 'knots',\n",
       " 'trainstation',\n",
       " 'fontana',\n",
       " 'helgar',\n",
       " 'embankment',\n",
       " 'becca',\n",
       " '0-',\n",
       " 'hunter',\n",
       " 'mz',\n",
       " 'dorm',\n",
       " 'fishman',\n",
       " 'painstaking',\n",
       " 'bounced',\n",
       " 'comprehensive',\n",
       " 'stuth',\n",
       " 'wery',\n",
       " 'governement',\n",
       " 'mans',\n",
       " 'lottery-ticket',\n",
       " 'regime',\n",
       " 'crashes',\n",
       " 'ache',\n",
       " 'thanapol',\n",
       " 'thatt',\n",
       " 'cardiologist',\n",
       " 'summit',\n",
       " 'handde',\n",
       " 'lazzy',\n",
       " 'verified',\n",
       " 'exhibited',\n",
       " 'caming',\n",
       " 'sleept',\n",
       " 'winter-clothes',\n",
       " 'films-stars',\n",
       " 'parades',\n",
       " 'bizarre',\n",
       " 'mashine',\n",
       " 'esspecially',\n",
       " 'triying',\n",
       " 'sibling',\n",
       " 'delivery',\n",
       " '00.00.0000y',\n",
       " 'thread',\n",
       " 'lourdes',\n",
       " 'atempt',\n",
       " 'differet',\n",
       " 'kyoto',\n",
       " 'minimise',\n",
       " 'tunique',\n",
       " 'steam',\n",
       " 'belo',\n",
       " 'expansive',\n",
       " 'apple',\n",
       " 'isolation',\n",
       " 'e',\n",
       " 'commerical',\n",
       " 'excessive',\n",
       " 'emperor',\n",
       " 'institution',\n",
       " 'whising',\n",
       " 'noway',\n",
       " 'secreatly',\n",
       " 'zalai',\n",
       " 'oportunety',\n",
       " 'prints',\n",
       " 'full-bloomed',\n",
       " 'hopeful',\n",
       " 'handphones',\n",
       " 'kimura',\n",
       " 'radiration',\n",
       " 'favorites',\n",
       " 'sunshuin',\n",
       " 'overherd',\n",
       " 'facilites',\n",
       " 'rotine',\n",
       " 'excepted',\n",
       " 'kary',\n",
       " 'defended',\n",
       " 'stylist',\n",
       " 'on-air',\n",
       " 'arabia',\n",
       " 'fete',\n",
       " 'dinning-hall',\n",
       " 'boxershorts',\n",
       " 'interssant',\n",
       " 'fascination',\n",
       " 'confidential',\n",
       " 'scandales',\n",
       " 'comenicate',\n",
       " 'insulating',\n",
       " 'importent',\n",
       " 'ethnographic',\n",
       " 'conferents',\n",
       " 'owr',\n",
       " 'satisfing',\n",
       " 'reserve',\n",
       " 'pancakes',\n",
       " 'suttendly',\n",
       " 'haves',\n",
       " 'petersburg',\n",
       " 'fouded',\n",
       " 'robotor',\n",
       " 'ameaising',\n",
       " 'hesitation',\n",
       " 'cockies',\n",
       " 'referent',\n",
       " 'angelina',\n",
       " 'homeless',\n",
       " 'chu',\n",
       " 'inguener',\n",
       " 'up0',\n",
       " 'rescently',\n",
       " 'nightdress',\n",
       " 'chiu',\n",
       " 'eaqual',\n",
       " 'computerizated',\n",
       " 'phoning',\n",
       " 'starsts',\n",
       " 'urgently',\n",
       " 'everone',\n",
       " 'proformed',\n",
       " 'encyclopaedia',\n",
       " 'traded',\n",
       " 'cared',\n",
       " 'chores',\n",
       " 'abroad.',\n",
       " 'cooling',\n",
       " 'explaind',\n",
       " 'leque',\n",
       " 'morocco',\n",
       " 'commanded',\n",
       " 'leeds',\n",
       " 'juny',\n",
       " 'anyways',\n",
       " 'inconvience',\n",
       " 'nessecary',\n",
       " 'rewritten',\n",
       " 'thoese',\n",
       " 'footh',\n",
       " 'spide',\n",
       " 'intersts',\n",
       " 'groue',\n",
       " 'exchanged',\n",
       " 'm',\n",
       " 'crept',\n",
       " 'transfer',\n",
       " 'refurbishing',\n",
       " 'oppertunate',\n",
       " 'repeared',\n",
       " 'lasy',\n",
       " 'recognizing',\n",
       " 'offen',\n",
       " 'nanny',\n",
       " 'bitter',\n",
       " 'semi-professers',\n",
       " 'flyers',\n",
       " 'quee',\n",
       " 'fries',\n",
       " 'downloaded',\n",
       " 'zygmunt',\n",
       " 'delights',\n",
       " 'precisions',\n",
       " 'rutines',\n",
       " 'sank',\n",
       " 'followings:-',\n",
       " 'seeside',\n",
       " 'whiteman',\n",
       " 'zuhal',\n",
       " 'pose',\n",
       " 'requere',\n",
       " 'wolk',\n",
       " 'clarinet',\n",
       " 'worsed',\n",
       " 'placement',\n",
       " 'futermore',\n",
       " 'enters',\n",
       " 'cased',\n",
       " 'hare',\n",
       " 'shudule',\n",
       " 'doctoral',\n",
       " 'computor',\n",
       " 'downstair',\n",
       " 'concience',\n",
       " 'destructed',\n",
       " 'md',\n",
       " 'not.',\n",
       " 'chan',\n",
       " 'booming',\n",
       " 'yawning',\n",
       " 'excel',\n",
       " 'shopmania',\n",
       " 'miniskirts',\n",
       " 'specifical',\n",
       " 'christies',\n",
       " 'purely',\n",
       " 'presume',\n",
       " 'hostels',\n",
       " 'conferences',\n",
       " 'opportiunity',\n",
       " 'threatens',\n",
       " 'quotas',\n",
       " 'fancy-dress',\n",
       " 'pension',\n",
       " 'budjet',\n",
       " 'bye-bye',\n",
       " 'gaultier',\n",
       " 'preserved',\n",
       " 'agency.',\n",
       " 'reasonaly-priced',\n",
       " 'integrated',\n",
       " 'grease',\n",
       " 'jhon',\n",
       " 'latested',\n",
       " 'picadelly',\n",
       " 'ski',\n",
       " 'shipbuilding',\n",
       " 'sigone',\n",
       " 'reacted',\n",
       " 'alexy',\n",
       " 'unpossible',\n",
       " 'inconvinient',\n",
       " 'tyres',\n",
       " 'gilbert',\n",
       " 'modenism',\n",
       " 'hubert',\n",
       " 'bach',\n",
       " 'ill-fitted',\n",
       " 'appeard',\n",
       " 'voices',\n",
       " 'petrov',\n",
       " 'desagree',\n",
       " 'installing',\n",
       " 'induction',\n",
       " 'destroys',\n",
       " 'punch',\n",
       " 'ledia',\n",
       " 'yahoo',\n",
       " 'businessmen',\n",
       " 'sincelery',\n",
       " 'mentenance',\n",
       " 'addresses',\n",
       " 'maks',\n",
       " 'spectacles',\n",
       " 'bones',\n",
       " 'not-ever-heard',\n",
       " 'prisonner',\n",
       " 'exercises',\n",
       " 'nursing',\n",
       " 'kak',\n",
       " 'inaccurate',\n",
       " 'lossing',\n",
       " 'agust',\n",
       " 'organic',\n",
       " 'sympathize',\n",
       " 'enjyoi',\n",
       " 'mobilephone',\n",
       " 'swot',\n",
       " 'affront',\n",
       " 'layed',\n",
       " 'prooth',\n",
       " 'tempting',\n",
       " 'canalized',\n",
       " 'extra-activities',\n",
       " 'coache',\n",
       " 'nerds',\n",
       " 'sportman',\n",
       " 'relevent',\n",
       " 'extrabus',\n",
       " 'conveyed',\n",
       " 'generated',\n",
       " 'introdus',\n",
       " 'hairstylers',\n",
       " 'demonstation',\n",
       " 'regretting',\n",
       " 'ofcoure',\n",
       " 'departnent',\n",
       " 'cultivite',\n",
       " 'recomand',\n",
       " 'promontion',\n",
       " 'agressions',\n",
       " 'e-business',\n",
       " 'combines',\n",
       " 'lice',\n",
       " 'compehension',\n",
       " 'earnest',\n",
       " 'tile',\n",
       " 'lun',\n",
       " 'kidneys',\n",
       " 'soles',\n",
       " 'deteriorated',\n",
       " 'undesireble',\n",
       " 'doomed',\n",
       " 'bacck',\n",
       " 'omit',\n",
       " 'litter',\n",
       " 'desparately',\n",
       " 'positives',\n",
       " 'urban',\n",
       " 'battles',\n",
       " 'fade',\n",
       " 'effectivily',\n",
       " 'phrase',\n",
       " 'focused',\n",
       " 'foregive',\n",
       " 'juarez',\n",
       " 'confienence',\n",
       " 'althoung',\n",
       " 'leysin',\n",
       " 'volenteer',\n",
       " 'cabins.',\n",
       " 'accostomed',\n",
       " \"withou't\",\n",
       " 'alencar',\n",
       " 'fluid',\n",
       " 'constant',\n",
       " 'refurbished',\n",
       " 'sity',\n",
       " 'robotes',\n",
       " 'middle-east',\n",
       " 'occupies',\n",
       " 'barkely',\n",
       " 'dodgy-looking',\n",
       " 'understatement',\n",
       " 'multimedia',\n",
       " 'boasting',\n",
       " 'unconciously',\n",
       " 'neville',\n",
       " 'greenhouse',\n",
       " 'phatosub',\n",
       " 'conecting',\n",
       " 'clung',\n",
       " 'stimulate',\n",
       " 'extras',\n",
       " '=bv',\n",
       " 'popconcert',\n",
       " 'telefonnumber',\n",
       " 'menu',\n",
       " 'faan',\n",
       " 'busybodies',\n",
       " 'jams',\n",
       " 'red-faced',\n",
       " 'rebuild',\n",
       " 'decadence',\n",
       " 'clouthes',\n",
       " 'plaed',\n",
       " 'conpert',\n",
       " 'unanswerable',\n",
       " 'leve',\n",
       " 'v',\n",
       " 'casses',\n",
       " 'misuse',\n",
       " 'frieds',\n",
       " 'manufactory',\n",
       " 'agreeable',\n",
       " 'franchise',\n",
       " 'headmistress',\n",
       " 'sincerley',\n",
       " 'krol',\n",
       " 'sensirly',\n",
       " 'discoes',\n",
       " 'gasoline',\n",
       " 'heritages',\n",
       " 'dissappeared',\n",
       " 'enything',\n",
       " 'socond',\n",
       " 'hyun',\n",
       " 'sir/manager',\n",
       " 'shew',\n",
       " 'kozin',\n",
       " 'centainly',\n",
       " 'surprizingly',\n",
       " 'grammar',\n",
       " 'l',\n",
       " 'comfortbly',\n",
       " 'sonya',\n",
       " 'approximetively',\n",
       " 'extra-large',\n",
       " 'stevens',\n",
       " 'beek',\n",
       " 'w-f',\n",
       " 'carola',\n",
       " 'unsociable',\n",
       " 'beverages',\n",
       " 'testament',\n",
       " 'stod',\n",
       " 'posipole',\n",
       " 'hwa',\n",
       " 'compricate',\n",
       " 'dolce',\n",
       " 'alak',\n",
       " 'beg',\n",
       " 'geographie',\n",
       " 'moist',\n",
       " 'regretful',\n",
       " 'conbined',\n",
       " 'surprisinggly',\n",
       " 'disaventage',\n",
       " 'ernestina',\n",
       " 'terror',\n",
       " 'locations',\n",
       " 'pica',\n",
       " 'sweater',\n",
       " 'accountant',\n",
       " 'sake',\n",
       " 'interrupt',\n",
       " 'linking',\n",
       " 'shoulde',\n",
       " 'plesure',\n",
       " 'testifite',\n",
       " 'lock',\n",
       " 'ex.boyfriend',\n",
       " 'f.o.f.',\n",
       " 'clasrooms',\n",
       " 'tonight.',\n",
       " 'shopping-addicts',\n",
       " 'affirm',\n",
       " 'gize',\n",
       " 'plastic-fabrics',\n",
       " 'domain',\n",
       " 'charachter',\n",
       " 'ciling',\n",
       " 'easeyer',\n",
       " 'tiny',\n",
       " 'stearing',\n",
       " 'showers',\n",
       " 'admirer',\n",
       " 'headed',\n",
       " 'fourious',\n",
       " 'tolerant',\n",
       " 'vareiety',\n",
       " 'entrace',\n",
       " 'dull',\n",
       " 'lubraries',\n",
       " 'prooved',\n",
       " 'nember',\n",
       " 'destructions',\n",
       " 'resignation',\n",
       " 'programas',\n",
       " 'loyal',\n",
       " 'washing-machine',\n",
       " 'elgant',\n",
       " 'biotecnologies',\n",
       " 'eating-place',\n",
       " 'pefect',\n",
       " 'unpersonal',\n",
       " 'sympathic',\n",
       " 'especialized',\n",
       " 'sweetest',\n",
       " 'translate',\n",
       " 'compliated',\n",
       " 'ramel',\n",
       " 'leaft',\n",
       " ',,baker',\n",
       " 'course-',\n",
       " 'cass',\n",
       " 'pollins',\n",
       " 'scinerly',\n",
       " 'crystal',\n",
       " 'pirvacity',\n",
       " 'turm',\n",
       " 'salesgirl',\n",
       " 'spin',\n",
       " 'situeded',\n",
       " 'thak',\n",
       " 'deck',\n",
       " 'acche',\n",
       " 'networks',\n",
       " 'applauded',\n",
       " 'behaveare',\n",
       " 'roadie',\n",
       " 'addecuate',\n",
       " 'infidel',\n",
       " 'sientific',\n",
       " 'prepered',\n",
       " 'santigo',\n",
       " 'tic',\n",
       " 'pacefully',\n",
       " '0000-00',\n",
       " 'interval',\n",
       " 'mapy',\n",
       " 'estrã©s',\n",
       " 'compositors',\n",
       " 'hillsborough',\n",
       " 'transforme',\n",
       " 'herschel',\n",
       " 'keeness',\n",
       " 'popped',\n",
       " 'kang-nam',\n",
       " 'toothbrush',\n",
       " 'plece',\n",
       " 'cambrigge',\n",
       " 'comonly',\n",
       " 'mabe',\n",
       " 'nowthere',\n",
       " 'chairman',\n",
       " 'staders',\n",
       " '........',\n",
       " 'puncture',\n",
       " 'sclumbling',\n",
       " 'illegaly',\n",
       " 'runing',\n",
       " 'durty',\n",
       " 'hazard',\n",
       " 'repley',\n",
       " 'armies',\n",
       " 'artifitual',\n",
       " 'clasics',\n",
       " 'bruses',\n",
       " 'concerts..',\n",
       " 'built-in',\n",
       " 'specealized',\n",
       " 'earthquake',\n",
       " 'comper',\n",
       " 'kettle',\n",
       " 'unrealiable',\n",
       " 'abondone',\n",
       " 'fish-liked-suit',\n",
       " 'kazanova',\n",
       " 'peice',\n",
       " 'lunch-break',\n",
       " 'multi-choices',\n",
       " 'telefaxes',\n",
       " 'hairstyl',\n",
       " 'repplies',\n",
       " 'lou',\n",
       " 'automaticly',\n",
       " 'sewage',\n",
       " 'everywher',\n",
       " 'croara',\n",
       " 'destroing',\n",
       " 'cashiers',\n",
       " 'gotten',\n",
       " 'truble',\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.singletons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. This builds the underlying neural network architecture in the form of a tensorflow graph. \n",
    "\n",
    "   Broadly speaking, the word embeddings (with an option to preload from GloVe) and character embeddings (randomly initialized) are combined and fed as an input into a bidirectional LSTM, whose output then goes into an **attention** layer that is eventually used for unsupervised classification. \n",
    "\n",
    "   More details of the architecture can be found in the author's paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def run_experiment(config_path):\n",
    "    ...\n",
    "    model.construct_network()\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Do some tensorflow initialization (such as any defined tensorflow `Variable`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def run_experiment(config_path):\n",
    "    ...\n",
    "    model.initialize_session()\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. If a path to GloVe is specified in `config['preload_vectors']`, then the word embeddings which were initialized in the previous step will be overridden by GloVe embeddings (if the word cannot be found, the original embedding will be left unmodified)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def run_experiment(config_path):\n",
    "    ...\n",
    "    if config[\"preload_vectors\"] != None:\n",
    "        model.preload_word_embeddings(config[\"preload_vectors\"])\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Training occurs, and any results will be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def run_experiment(config_path):\n",
    "    ...\n",
    "    results_train = process_sentences(data_train, model, is_training=True, learningrate=learningrate, \n",
    "                                      config=config, name=\"train\")\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `process_sentences`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Before entering the model, the raw data is converted into batches (default config = of equal size 32). Each batch contains the index of the data instead of the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def process_sentences(data, model, is_training, learningrate, config, name):\n",
    "    ...\n",
    "    batches_of_sentence_ids = create_batches_of_sentence_ids(data, config[\"batch_equal_size\"], config[\"max_batch_size\"])\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 32\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
      "\n",
      "length: 32\n",
      "[32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
      "\n",
      "length: 32\n",
      "[64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batches_of_sentence_ids = create_batches_of_sentence_ids(data_train, config['batch_equal_size'], config['max_batch_size'])\n",
    "\n",
    "# First 3 examples\n",
    "for i in batches_of_sentence_ids[:3]:\n",
    "    print('length: {}\\n{}\\n'.format(len(i), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The model does training batch by batch, and records the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```python \n",
    "def process_sentences(data, model, is_training, learningrate, config, name):\n",
    "    ...\n",
    "    for sentence_ids_in_batch in batches_of_sentence_ids:\n",
    "        batch = [data[i] for i in sentence_ids_in_batch]\n",
    "        cost, sentence_scores, token_scores_list = model.process_batch(batch, is_training, learningrate)\n",
    "        evaluator.append_data(cost, batch, sentence_scores, token_scores_list)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
